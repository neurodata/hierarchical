{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from skimage.transform import resize\n",
    "from proglearn.forest import LifelongClassificationForest as l2f\n",
    "from proglearn.transformers import TreeClassificationTransformer as transformer\n",
    "from proglearn.voters import TreeClassificationVoter as voter\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /home/AzureUser/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c4807e08b24614b2c4d1329ba2bacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=100441675.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "conv_transformer = models.resnext50_32x4d(pretrained=True)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainset.data = ((trainset.data / 255) - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])\n",
    "trainset.data = torch.tensor(trainset.data.transpose(0,3,1,2)).float()\n",
    "trainset.data = conv_transformer(trainset.data).detach().numpy()\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testset.data = ((testset.data / 255) - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])\n",
    "testset.data = torch.tensor(testset.data.transpose(0,3,1,2)).float()\n",
    "testset.data = conv_transformer(testset.data).detach().numpy()\n",
    "\n",
    "# Unsupervised projection into lower dimension\n",
    "pca = PCA(n_components=32)\n",
    "pca.fit(trainset.data)\n",
    "\n",
    "trainset.data = pca.transform(trainset.data)\n",
    "testset.data = pca.transform(testset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_to_fine_map = {\n",
    "'aquatic_mammals': ['beaver', 'dolphin', 'otter', 'seal', 'whale'],\n",
    "'fish': ['aquarium_fish', 'flatfish', 'ray', 'shark', 'trout'],\n",
    "'flowers': ['orchid', 'poppy', 'rose', 'sunflower', 'tulip'],\n",
    "'food_containers': ['bottle', 'bowl', 'can', 'cup', 'plate'],\n",
    "'fruit_and_vegetables': ['apple', 'mushroom', 'orange', 'pear', 'sweet_pepper'],\n",
    "'household_electrical_devices': ['clock', 'keyboard', 'lamp', 'telephone', 'television'],\n",
    "'household_furniture': ['bed', 'chair', 'couch', 'table', 'wardrobe'],\n",
    "'insects': ['bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach'],\n",
    "'large_carnivores': ['bear', 'leopard', 'lion', 'tiger', 'wolf'],\n",
    "'large_man-made_outdoor_things': ['bridge', 'castle', 'house', 'road', 'skyscraper'],\n",
    "'large_natural_outdoor_scenes': ['cloud', 'forest', 'mountain', 'plain', 'sea'],\n",
    "'large_omnivores_and_herbivores': ['camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo'],\n",
    "'medium-sized_mammals': ['fox', 'porcupine', 'possum', 'raccoon', 'skunk'],\n",
    "'non-insect_invertebrates': ['crab', 'lobster', 'snail', 'spider', 'worm'],\n",
    "'people': ['baby', 'boy', 'girl', 'man', 'woman'],\n",
    "'reptiles': ['crocodile', 'dinosaur', 'lizard', 'snake', 'turtle'],\n",
    "'small mammals': ['hamster', 'mouse', 'rabbit', 'shrew', 'squirrel'],\n",
    "'trees': ['maple_tree', 'oak_tree', 'palm_tree', 'pine_tree', 'willow_tree'],\n",
    "'vehicles_1': ['bicycle', 'bus', 'motorcycle', 'pickup_truck', 'train'],\n",
    "'vehicles_2': ['lawn_mower', 'rocket', 'streetcar', 'tank', 'tractor']\n",
    "}\n",
    "\n",
    "coarse_number_to_coarse_name = {i: name for i, name in enumerate(coarse_to_fine_map)}\n",
    "\n",
    "def fine_to_coarse(coarse_to_fine):\n",
    "    fine_to_coarse_map = {}\n",
    "    for key in coarse_to_fine:\n",
    "        fines = coarse_to_fine[key]\n",
    "        for f in fines:\n",
    "            fine_to_coarse_map[f] = key\n",
    "            \n",
    "    return fine_to_coarse_map\n",
    "\n",
    "fine_to_coarse_map = fine_to_coarse(coarse_to_fine_map)\n",
    "\n",
    "fine_number_to_fine_name = {i: name for i, name in enumerate(trainset.classes)}\n",
    "\n",
    "for i in range(100):\n",
    "    fine_to_coarse_map[fine_number_to_fine_name[i]]\n",
    "    \n",
    "coarse_name_to_coarse_number = {name: i for i, name in enumerate(coarse_to_fine_map)}\n",
    "\n",
    "coarse_targets = np.array([coarse_name_to_coarse_number[fine_to_coarse_map[fine_number_to_fine_name[y]]] for y in trainset.targets])\n",
    "idx_by_coarse = [np.where(coarse_targets == y)[0] for y in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [6:24:46<00:00, 4617.30s/it]  \n"
     ]
    }
   ],
   "source": [
    "# n_props = np.arange(1, 11) / 10\n",
    "n_props = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "models = {prop: {'coarse': None, \n",
    "                 'fine': {i: None for i in range(len(idx_by_coarse))},\n",
    "                 'flat': None,\n",
    "                } for prop in n_props}\n",
    "\n",
    "# Resource control\n",
    "n_trees_coarse = 200\n",
    "n_trees_fine = 25\n",
    "# n_trees_flat = 10\n",
    "n_trees_flat = n_trees_coarse + (20 * n_trees_fine)\n",
    "\n",
    "for i, prop in enumerate(tqdm(n_props)):\n",
    "    indices_by_coarse_label = [np.random.choice(ibc, size = int(prop*len(ibc)), replace=False) for ibc in idx_by_coarse]\n",
    "    X = trainset.data[np.concatenate(indices_by_coarse_label)]\n",
    "    \n",
    "    coarse_forest = l2f(n_estimators=n_trees_coarse,\n",
    "                        default_finite_sample_correction=False,\n",
    "                        default_max_depth=None)\n",
    "    coarse_forest.add_task(X, coarse_targets[np.concatenate(indices_by_coarse_label)])\n",
    "    models[prop]['coarse'] = coarse_forest\n",
    "#     print('done coarse')\n",
    "    \n",
    "    flat_forest = l2f(n_estimators=n_trees_flat,\n",
    "                        default_finite_sample_correction=False,\n",
    "                        default_max_depth=None)\n",
    "    flat_forest.add_task(X, np.array(trainset.targets)[np.concatenate(indices_by_coarse_label)])\n",
    "    models[prop]['flat'] = flat_forest\n",
    "#     print('done flat')\n",
    "    \n",
    "    for j, inds in enumerate(indices_by_coarse_label):\n",
    "        X = trainset.data[inds]\n",
    "        \n",
    "        fine_forest = l2f(n_estimators=n_trees_fine, \n",
    "                               default_finite_sample_correction=False, \n",
    "                               default_max_depth=None\n",
    "                              )\n",
    "        fine_forest.add_task(X, np.array(trainset.targets)[inds])\n",
    "        models[prop]['fine'][j] = fine_forest\n",
    "#         print('done fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = {'hierarchical': [], 'flat': []}\n",
    "\n",
    "for i, prop in enumerate(n_props):\n",
    "    hierarchical_posteriors = np.zeros((testset.data.shape[0], 100))\n",
    "    coarse_posteriors = models[prop]['coarse'].predict_proba(testset.data, 0)\n",
    "    \n",
    "    for j, ibc in enumerate(idx_by_coarse):\n",
    "        fine_label_indices = np.unique(np.array(trainset.targets)[ibc]).astype(int)\n",
    "        \n",
    "        temp_fine_posteriors = models[prop]['fine'][j].predict_proba(testset.data, 0)\n",
    "        hierarchical_posteriors[:, fine_label_indices] = np.multiply(coarse_posteriors[:, j],\n",
    "                                                                     temp_fine_posteriors.T\n",
    "                                                                    ).T\n",
    "        \n",
    "    yhat_hc = np.argmax(hierarchical_posteriors, axis=1)\n",
    "    accuracies['hierarchical'].append(np.mean(yhat_hc == np.array(testset.targets)))\n",
    "                                                                    \n",
    "    flat_posteriors = models[prop]['flat'].predict_proba(testset.data, 0)\n",
    "    yhat_flat = np.argmax(flat_posteriors, axis=1)\n",
    "    accuracies['flat'].append(np.mean(yhat_flat == np.array(testset.targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "colors = sns.color_palette(\"Set1\", n_colors=2)\n",
    "\n",
    "types = ['hierarchical', 'flat']\n",
    "\n",
    "for i, typ in enumerate(types):\n",
    "    ax.plot(n_props, accuracies[typ], c=colors[i], label=typ)\n",
    "    \n",
    "ax.set_title('Accuracy on CIFAR100', fontsize=18)\n",
    "ax.set_xlabel('proportion of training data', fontsize=18)\n",
    "ax.set_ylabel('accuracy', fontsize=18)\n",
    "ax.set_yticks([0.08, 0.09, 0.1, 0.11])\n",
    "ax.set_xticks([0.1, 0.3, 0.5])\n",
    "\n",
    "ax.tick_params(labelsize=16)\n",
    "ax.legend(fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figures/accuracy_cifar100_resource_controlled.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hc",
   "language": "python",
   "name": "hc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
