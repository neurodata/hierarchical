{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 13675447762979434872,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 7831080160\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 10509027580462840258\n",
       " physical_device_desc: \"device: 0, name: Tesla M60, pci bus id: 8dc8:00:00.0, compute capability: 5.2\",\n",
       " name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 7831080160\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 12977450762773506768\n",
       " physical_device_desc: \"device: 1, name: Tesla M60, pci bus id: af13:00:00.0, compute capability: 5.2\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization,GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from keras.datasets import cifar100\n",
    "from collections import defaultdict\n",
    "from tensorflow.keras.applications import resnet\n",
    "import cv2\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, y_train, x_test, y_test = pickle.load(open('/home/weiwya/teamdrive/weiwei-scratch/cifar_resnet50_embed.p', 'rb'))\n",
    "# print(x_train.shape, x_test.shape)\n",
    "# input_dim = x_train.shape[-1]\n",
    "\n",
    "(fx, fy), (fxx, fyy) = cifar100.load_data()\n",
    "(cx, cy), (cxx, cyy) = cifar100.load_data(label_mode='coarse') \n",
    "\n",
    "#get label converstions\n",
    "fine_to_coarse = {}\n",
    "for f,c in zip( fy, cy):\n",
    "    fine_to_coarse[f[0]] = c[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array( [ resnet.preprocess_input(cv2.resize(x,(224,224))) for x in fx])\n",
    "x_test =  np.array( [ resnet.preprocess_input(cv2.resize(x,(224,224))) for x in fxx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1042/1042 [==============================] - 1295s 953ms/step - loss: 2.1807 - accuracy: 0.3297\n",
      "Epoch 2/10\n",
      "1042/1042 [==============================] - 702s 674ms/step - loss: 1.2918 - accuracy: 0.5854\n",
      "Epoch 3/10\n",
      "1042/1042 [==============================] - 705s 677ms/step - loss: 0.9898 - accuracy: 0.6840\n",
      "Epoch 4/10\n",
      "1042/1042 [==============================] - 706s 677ms/step - loss: 0.7744 - accuracy: 0.7494\n",
      "Epoch 5/10\n",
      "1042/1042 [==============================] - 704s 675ms/step - loss: 0.6065 - accuracy: 0.8021\n",
      "Epoch 6/10\n",
      "1042/1042 [==============================] - 705s 676ms/step - loss: 0.4721 - accuracy: 0.8460\n",
      "Epoch 7/10\n",
      "1042/1042 [==============================] - 705s 677ms/step - loss: 0.3493 - accuracy: 0.8867\n",
      "Epoch 8/10\n",
      "1042/1042 [==============================] - 703s 675ms/step - loss: 0.2623 - accuracy: 0.9171\n",
      "Epoch 9/10\n",
      "1042/1042 [==============================] - 705s 677ms/step - loss: 0.2120 - accuracy: 0.9325\n",
      "Epoch 10/10\n",
      "1042/1042 [==============================] - 704s 675ms/step - loss: 0.1672 - accuracy: 0.9461\n"
     ]
    }
   ],
   "source": [
    "input_shapes = (224, 224, 3)\n",
    "\n",
    "def build_model(base_model, n_classes):\n",
    "#     base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    y = Dense(n_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input,\n",
    "                  outputs=y)\n",
    "    return model\n",
    "\n",
    "\n",
    "base_model = resnet.ResNet50(include_top=False,\n",
    "                                   weights='imagenet',\n",
    "                                   input_shape=input_shapes)\n",
    "model_coarse = build_model(base_model, 20)\n",
    "model_coarse.compile(optimizer='adam',\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "history = model_coarse.fit(x_train, to_categorical(cy),\n",
    "                          epochs= 10,\n",
    "                          verbose=True, \n",
    "                          batch_size=48,\n",
    "                          shuffle = True,\n",
    "\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 155s 493ms/step - loss: 1.2438 - accuracy: 0.7055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2437515258789062, 0.7055000066757202]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_coarse.evaluate( x_test, to_categorical(cyy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 10000 of 50000 for training\n",
      "313/313 [==============================] - 0s 866us/step - loss: 2.8157 - accuracy: 0.6352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.81571626663208, 0.635200023651123]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_percent = 0.2\n",
    "train_size = int(train_percent * len(x_train))\n",
    "\n",
    "print('using %i of %i for training' %(train_size, len(x_train)))\n",
    "\n",
    "#tain coarse classifer\n",
    "y_train_coarse = to_categorical([fine_to_coarse[n[0]] for n in y_train])\n",
    "y_test_coarse = to_categorical([fine_to_coarse[n[0]] for n in y_test])\n",
    "\n",
    "model_coarse = Sequential()\n",
    "model_coarse.add(Dense(256, activation='relu', input_shape=(input_dim, )))\n",
    "model_coarse.add(BatchNormalization())\n",
    "model_coarse.add(Dropout(.25))\n",
    "model_coarse.add(Dense(y_train_coarse.shape[-1], activation='softmax'))\n",
    "model_coarse.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model_coarse.fit(x_train[:train_size], y_train_coarse[:train_size], \n",
    "                    epochs = 100, \n",
    "                    verbose = False,\n",
    "                    batch_size=48,\n",
    "                    shuffle = True,\n",
    "                   )\n",
    "\n",
    "\n",
    "\n",
    "model_coarse.evaluate( x_test, y_test_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_coarse_class(tx, ty, txx, tyy, wanted_class, fine_to_coarse, return_percent=0.2):\n",
    "\n",
    "    kept_labels = []\n",
    "    for k, v, in fine_to_coarse.items():\n",
    "        if v == wanted_class:\n",
    "            kept_labels.append(k)\n",
    "    kept_labels = set(kept_labels)\n",
    "        \n",
    "    train_data, train_labels = [], []\n",
    "    test_data,  test_labels =  [], []\n",
    "    \n",
    "    for x, y in zip(tx, ty):\n",
    "        y=y[0]\n",
    "        if y in kept_labels:\n",
    "            train_data.append(x)\n",
    "            train_labels.append(y)\n",
    "            \n",
    "    for x, y  in zip (txx, tyy):\n",
    "        y=y[0]\n",
    "        if y in kept_labels:\n",
    "            test_data.append(x)\n",
    "            test_labels.append(y)\n",
    "            \n",
    "            \n",
    "    #TODO:: find better way to convert the labels\n",
    "    ll =  np.unique(train_labels)\n",
    "    label_convert = {n:i for i, n in enumerate(ll)}\n",
    "    inverse_label_convert = {v:k for k, v in label_convert.items()}\n",
    "    \n",
    "    \n",
    "    train_labels = to_categorical([label_convert[n] for n in train_labels])\n",
    "    test_labels = to_categorical([label_convert[n] for n in test_labels])\n",
    "    \n",
    "    \n",
    "    return_size = int(len(train_data) * return_percent)\n",
    "    \n",
    "    return  np.array(train_data)[:return_size], \\\n",
    "            train_labels[:return_size],\\\n",
    "            np.array(test_data),\\\n",
    "            test_labels, \\\n",
    "            inverse_label_convert\n",
    "\n",
    "\n",
    "\n",
    "def train_fine_clf(tx, ty, txx, tyy, wanted_class, fine_to_coarse, epochs=100, verbose=False):\n",
    "    train_data, train_labels, test_data, test_labels, lookup_hash \\\n",
    "        = get_data_coarse_class(tx, ty, txx, tyy, wanted_class, fine_to_coarse)\n",
    "    \n",
    "    model_fine = Sequential()\n",
    "    model_fine.add(Dense(256, activation='relu', input_shape=(input_dim, )))\n",
    "    model_fine.add(BatchNormalization())\n",
    "    model_fine.add(Dropout(.25))\n",
    "    model_fine.add(Dense(train_labels.shape[-1], activation='softmax'))\n",
    "    model_fine.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    model_fine.fit(train_data, train_labels, \n",
    "                    epochs = epochs, \n",
    "                    verbose = verbose,\n",
    "                    batch_size=48,\n",
    "                    shuffle = True,\n",
    "                    )\n",
    "    model_fine.evaluate(test_data, test_labels)\n",
    "    return model_fine, lookup_hash\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: 0\n",
      "16/16 [==============================] - 0s 905us/step - loss: 2.8713 - accuracy: 0.5280\n",
      "\n",
      "task: 1\n",
      "16/16 [==============================] - 0s 952us/step - loss: 2.3033 - accuracy: 0.6260\n",
      "\n",
      "task: 2\n",
      "16/16 [==============================] - 0s 927us/step - loss: 2.3941 - accuracy: 0.5560\n",
      "\n",
      "task: 3\n",
      "16/16 [==============================] - 0s 831us/step - loss: 1.8772 - accuracy: 0.6880\n",
      "\n",
      "task: 4\n",
      "16/16 [==============================] - 0s 960us/step - loss: 1.8125 - accuracy: 0.7020\n",
      "\n",
      "task: 5\n",
      "16/16 [==============================] - 0s 900us/step - loss: 1.3608 - accuracy: 0.7780\n",
      "\n",
      "task: 6\n",
      "16/16 [==============================] - 0s 837us/step - loss: 2.2900 - accuracy: 0.6180\n",
      "\n",
      "task: 7\n",
      "16/16 [==============================] - 0s 893us/step - loss: 1.8240 - accuracy: 0.6560\n",
      "\n",
      "task: 8\n",
      "16/16 [==============================] - 0s 852us/step - loss: 1.8011 - accuracy: 0.6860\n",
      "\n",
      "task: 9\n",
      "16/16 [==============================] - 0s 845us/step - loss: 1.9231 - accuracy: 0.6780\n",
      "\n",
      "task: 10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.8114 - accuracy: 0.7180\n",
      "\n",
      "task: 11\n",
      "16/16 [==============================] - 0s 882us/step - loss: 1.4395 - accuracy: 0.7700\n",
      "\n",
      "task: 12\n",
      "16/16 [==============================] - 0s 878us/step - loss: 2.3325 - accuracy: 0.6260\n",
      "\n",
      "task: 13\n",
      "16/16 [==============================] - 0s 883us/step - loss: 1.6601 - accuracy: 0.7200\n",
      "\n",
      "task: 14\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.7447 - accuracy: 0.3740\n",
      "\n",
      "task: 15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.4409 - accuracy: 0.6280\n",
      "\n",
      "task: 16\n",
      "16/16 [==============================] - 0s 844us/step - loss: 3.0953 - accuracy: 0.5420\n",
      "\n",
      "task: 17\n",
      "16/16 [==============================] - 0s 872us/step - loss: 3.3796 - accuracy: 0.4920\n",
      "\n",
      "task: 18\n",
      "16/16 [==============================] - 0s 970us/step - loss: 1.5894 - accuracy: 0.6840\n",
      "\n",
      "task: 19\n",
      "16/16 [==============================] - 0s 913us/step - loss: 1.3117 - accuracy: 0.7740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fine_models = {}\n",
    "\n",
    "for i in range(y_train_coarse.shape[1]):\n",
    "    print('task: %i' %i)\n",
    "    fine_models[i] = train_fine_clf(x_train, y_train, x_test, y_test, i, fine_to_coarse)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_weighted (x_data, coarse_model, fine_models, total_class=100):\n",
    "    coarse_weights = coarse_model.predict(x_data)    \n",
    "    predictions = np.zeros((x_data.shape[0], total_class))\n",
    "    \n",
    "    for k, v in fine_models.items():\n",
    "        fine_model = v[0]\n",
    "        label_hash = v[1]\n",
    "        p = coarse_weights[:, k].reshape(-1,1) * fine_model.predict(x_data)\n",
    "        for i in range(p.shape[1]):\n",
    "            predictions[:, label_hash[i]] += p[:,i]\n",
    "    return predictions\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4523\n"
     ]
    }
   ],
   "source": [
    "pp =predict_weighted(x_test, model_coarse, fine_models)\n",
    "pp = np.argmax(pp, axis=1)\n",
    "y_test_flatten = y_test.flatten()\n",
    "\n",
    "print(np.sum(pp == y_test_flatten)/ len(pp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 857us/step - loss: 4.7427 - accuracy: 0.4663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.742698669433594, 0.46630001068115234]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = Sequential()\n",
    "base_model.add(Dense(256, activation='relu', input_shape=(input_dim, )))\n",
    "base_model.add(BatchNormalization())\n",
    "base_model.add(Dropout(.25))\n",
    "base_model.add(Dense(100, activation='softmax'))\n",
    "base_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "base_model.fit(x_train[:train_size], to_categorical(y_train)[:train_size], \n",
    "                    epochs = 100, \n",
    "                    verbose = False,\n",
    "                    batch_size=48,\n",
    "                    shuffle = True,\n",
    "                    )\n",
    "base_model.evaluate(x_test, to_categorical(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
